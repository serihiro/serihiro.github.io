<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Kazuhiro Serizawa&#39;s profile page</title>
    <link>https://serihiro.github.io/</link>
    <description>Recent content in Home on Kazuhiro Serizawa&#39;s profile page</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://serihiro.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Accelerating Machine Learning I/O by Overlapping Data Staging and Mini-batch Generations</title>
      <link>https://serihiro.github.io/publications/bdcat/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://serihiro.github.io/publications/bdcat/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://speakerdeck.com/serihiro/o-by-overlapping-data-staging-and-mini-batch-generations&#34;&gt;The slide of this talk&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;The training dataset used in deep neural networks (DNNs) keeps on increasing. When a training dataset grows larger, the reading performance of such a large training dataset becomes a problem. A high-performance computing (HPC) cluster has high performance I/O storage devices, for example, NVMe SSD, as local storage on each compute node. This high-performance I/O storage can mitigate the I/O bottleneck. However, such storage devices provide only temporary storage, therefore the users have to copy the training dataset from shared storage (such as Lustre) into local storage. Large datasets (over a few hundred GiB) takes a long time to copy the datasets between local storage and shared storage. To solve this problem, we propose a method to conceal the time spent on copying dataset to local storage by overlapping the copying and reading of training data. We implemented the proposed method at the machine learning framework Chainer. The results of our experiments showed that the read I/O bandwidth of our method improved from 1.38 times to 6.19 times compared with reading the dataset from Lustre directly using Chainer standard class. Moreover, evaluation of data parallel training showed that our method improved the performance from 1.26 times to 1.74 times for the same comparison.&lt;/p&gt;</description>
    </item>
    <item>
      <title>大規模機械学習訓練におけるI/O性能の高速化</title>
      <link>https://serihiro.github.io/publications/hpc170/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://serihiro.github.io/publications/hpc170/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://speakerdeck.com/serihiro/hpc170-slide&#34;&gt;The slide of this talk&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;深層ニューラルネットワークに使用される訓練データの規模は年々増加しており，深層ニューラルネットワークの訓練処理において訓練データの read I/O は無視できないボトルネックになりつつある．ノードローカルストレージとして搭載された SSD などの I/O が高速なストレージデバイスを使用することで read I/O の高速化は可能であるが，HPC クラスタにおいては毎回訓練データセットのファイルコピーが毎回必要であるという課題がある．また，HPC クラスタの計算ノードからネットワークを経由してアクセス可能な外部ストレージは訓練データセットをファイルコピーせずに訓練処理を開始できるが，SSD ほどのバンド幅は見込めない．本研究では，ノードローカルストレージと外部ストレージを組み合わせて使用することで事前に訓練データセットのコピーをせずに read I/O を高速化する手法を提案する．提案手法を機械学習フレームワークである Chainer に実装し，Chainer が提供する並列に訓練データを read する機能をベースラインとして，read I/O 性能を自作したベンチマークによって比較したところ，Lustre に訓練データを配置した場合のベースラインよりも，より少ないプロセス数を使用して最大で約 20% 高い read I/O 性能を達成できることを示した．データ並列訓練における 10 epoch の訓練時間の比較では，訓練データセットのファイルコピーに要する時間を考慮するとベースラインと SSD の組み合わせよりも訓練処理時間を短縮できることを示した．一方で，データ並列訓練においては read I/O ではなく AllReduce による処理時間が律速するため，ストレージ間の I/O 性能が処理時間に反映されにくいという，データ並列訓練の所要時間における特性を明らかにした．&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bibtex&#34; data-lang=&#34;bibtex&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@inproceedings&lt;/span&gt; { IPSJ-HPC170:serizawa,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;author&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{芹沢 和洋} and {建部 修見}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;institution&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{筑波大学大学院システム情報工学研究科コンピュータサイエンス専攻}, {筑波大学計算科学研究センター}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{深層ニューラルネットワークにおける訓練高速化のための自動最適化}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;year&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{2019}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;volume&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{2019-HPC-170}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;number&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{9}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;pages&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;{1--12}&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;booktitle&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{IPSJ SIG Technical Report}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;url&lt;/span&gt;= &lt;span style=&#34;color:#e6db74&#34;&gt;{http://id.nii.ac.jp/1001/00198056/}&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;note&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;{(In Japanese)}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>深層ニューラルネットワークにおける訓練高速化のための自動最適化</title>
      <link>https://serihiro.github.io/publications/hpc168/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://serihiro.github.io/publications/hpc168/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://speakerdeck.com/serihiro/shen-ceng-niyurarunetutowakuniokeruxun-lian-gao-su-hua-falsetamefalsezi-dong-zui-shi-hua&#34;&gt;The slide of this talk&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;深層ニューラルネットワークの訓練には大量のデータが必要となり，訓練処理時間の長期化が問題となっている．訓練時間の短縮方法として，複数の訓練データを用いて訓練処理を行うミニバッチ訓練という手法が知られている．本研究では，訓練処理時間と関連性が考えられる，訓練処理中の GPU 利用率を最大化するという最適化手法を用いて．訓練処理時間を可能な限り最短にすることができるミニバッチサイズを決定する方法を提案した．提案手法を深層学習フレームワークである Chainer を用いて実装した．Cifar 100 と ImageNet の 2 種類の画像データセットおよび VGG 16 と ResNet 50 の 2 種類の畳み込みニューラルネットワークを用いて提案手法の評価を行った結果，GPU 利用率のみを最大化するアプローチでは訓練処理速度を最短とするミニバッチサイズを決定することは困難であるという結論となった．一方で，データセットごとに訓練処理中の GPU 利用率とミニバッチサイズとの間の相関性に異なる傾向が観察され，データサイズに起因するボトルネックが GPU 利用を阻害している可能性が発見された．&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bibtex&#34; data-lang=&#34;bibtex&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@inproceedings&lt;/span&gt; { IPSJ-HPC168:serizawa,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;author&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{芹沢 和洋} and {建部 修見}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;institution&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{筑波大学大学院システム情報工学研究科コンピュータサイエンス専攻}, {筑波大学計算科学研究センター}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{深層ニューラルネットワークにおける訓練高速化のための自動最適化}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;year&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{2019}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;volume&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{2019-HPC-168}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;number&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{25}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;pages&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;{1--10}&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;booktitle&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{IPSJ SIG Technical Report}&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;url&lt;/span&gt;= &lt;span style=&#34;color:#e6db74&#34;&gt;{http://id.nii.ac.jp/1001/00194707/}&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;note&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;{(In Japanese)}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
  </channel>
</rss>
