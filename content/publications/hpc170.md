---
title: "大規模機械学習訓練におけるI/O性能の高速化"
date: 2019-07-24
pubtype: "Domestic conference"
featured: true
description: "The academic paper that I submitted to \"情報処理学会 第170回 HPC 研究会報告 (HPC170)\""
tags: ["Proceedings", "Domestic Conference"]
link: "http://id.nii.ac.jp/1001/00198056/"
sitemap:
  priority : 0.5
---

[The slide of this talk](https://speakerdeck.com/serihiro/hpc170-slide)

深層ニューラルネットワークに使用される訓練データの規模は年々増加しており，深層ニューラルネットワークの訓練処理において訓練データの read I/O は無視できないボトルネックになりつつある．ノードローカルストレージとして搭載された SSD などの I/O が高速なストレージデバイスを使用することで read I/O の高速化は可能であるが，HPC クラスタにおいては毎回訓練データセットのファイルコピーが毎回必要であるという課題がある．また，HPC クラスタの計算ノードからネットワークを経由してアクセス可能な外部ストレージは訓練データセットをファイルコピーせずに訓練処理を開始できるが，SSD ほどのバンド幅は見込めない．本研究では，ノードローカルストレージと外部ストレージを組み合わせて使用することで事前に訓練データセットのコピーをせずに read I/O を高速化する手法を提案する．提案手法を機械学習フレームワークである Chainer に実装し，Chainer が提供する並列に訓練データを read する機能をベースラインとして，read I/O 性能を自作したベンチマークによって比較したところ，Lustre に訓練データを配置した場合のベースラインよりも，より少ないプロセス数を使用して最大で約 20% 高い read I/O 性能を達成できることを示した．データ並列訓練における 10 epoch の訓練時間の比較では，訓練データセットのファイルコピーに要する時間を考慮するとベースラインと SSD の組み合わせよりも訓練処理時間を短縮できることを示した．一方で，データ並列訓練においては read I/O ではなく AllReduce による処理時間が律速するため，ストレージ間の I/O 性能が処理時間に反映されにくいという，データ並列訓練の所要時間における特性を明らかにした．

```bibtex
@techreport{weko_198146_1,
  author = "芹沢,和洋 and 建部,修見",
  title = "大規模機械学習訓練におけるI/O性能の高速化",
  year = "2019",
  institution = "筑波大学大学院システム情報工学研究科コンピュータサイエンス専攻, 筑波大学計算科学研究センター",
  number = "9",
  month = "jul"
}
```
